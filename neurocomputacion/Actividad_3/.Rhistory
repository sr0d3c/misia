suma <- 4+5
suma
runif(3)
runif(10,4,5)
runif(3,4,5)
(a <- runif(10,4,5))
ls()
objects()
rm(list=ls())
mean(a)
(a <- runif(3))
mean(a)
x <- 4+5
# Un numero se almacena en R como un vector de longitud 1
x
x[2] <- 10
x
rnorm(2, mean = 1:2)
rnorm(5, mean = 1:2)
rnorm(5, mean = 1:4)
rnorm(5, mean = 1:4)
rnorm(5, mean = 1:4)
rnorm(5, mean = 1:2)
# En R se usa la función list() para crear una lista
(alumno <- list("Jose",47,TRUE))
# str permite acceder al contenido de la lista
str(alumno)
length(alumno)
mode(alumno)
class(alumno)
# La funcion names permite crear o cambiar los nombres de los elementos de una lista
names(alumno) <- c("nombre","edad","estado")
alumno
names(alumno)
# La indexacion se realiza mediante los operadores [], que permiten obtener un elemento en formato lista
alumno[1]
# La indexacion se realiza mediante los operadores [], que permiten obtener un elemento en formato lista
alumno[2]
# o se puede realizar la idexacion mediante el operador [[]] o $ que permiten recuperar los elementos de la lista en el formato de almacenamiento original
alumno[[1]]
mode(alumno[[1]])
alumno$nombre
# la funcion data.frame se utiliza para crear objetos del tipo data.frame
datos <- data.frame(nombre = c("jose","juan","pedro"), edad = c(47,54,34), estado = c(TRUE,FALSE,TRUE))
View(datos)
datos
str(datos)
mode(datos)
class(datos)
datos[1,2]
datos[1,]
datos[,1]
datos[1,"edad"]
# La funcion matrix se usa para construir matrices en R
runif(10)
mat <- matrix(nrow = 2, ncol = 5)
dim(mat)
nrow(mat)
ncol(mat)
rownames(mat)
# Divide el gráfico en 2 figuras
par(mfrow = c(1,2))
# Histogramas de las distribuciones normales con media = 0 y std = 1
hist(rnorm(20))
hist(rnorm(2000))
hist(rnorm(20000))
# Histogramas de las distribuciones normales con media = 0 y std = 1
hist(rnorm(20))
# ACTIVIDAD
x <- runif(20,min = 0,max = 10)
? runif
# Matriz de dos dimensiones
M <- matrix(seq(1,16),4,4)
View(M)
# Aplica min a las filas
apply(M, 1, min)
M
View(M)
? max
# Aplica max a las columnas
apply(M, 2, max)
# Array de 3 dimensiones
M <- array(seq(12),dim = c(4,4,2))
M
# Aplica sum sobre la 2da y 3ra dimension del array
apply(M, 1, sum)
# Array de 3 dimensiones
M <- array(seq(32),dim = c(4,4,2))
M
# Aplica sum sobre la 2da y 3ra dimension del array
apply(M, 1, sum)
# Aplica sum sobre la 3ra dimension
apply(M,,c(1,2),sum)
# Aplica sum sobre la 3ra dimension
apply(M,c(1,2),sum)
# LAPPLY
# Lista con 3 elementos, cada uno de ellos un vector
x <- list(a = 1, b = 1:3, c = 10:100)
View(x)
lapply(x, FUN = length)
lapply(x, FUN = sum)
# SAPPLY
y <- list(a = 1, b = 1:3, c = 10:100)
# Comparar el resultado con la versión anterior de lapply
sapply(y, FUN = length)
# Obtendríamos el mismo resultados usando unlist(lapply...)
unlist(lapply(x, FUN = length))
sapply(x, FUN = sum)
# Lectura de un fichero
datos <- read.table(file = "datos_icb.txt",header = TRUE)
install caret
install.packages("caret")
install.packages("rtools")
install.packages("FSelector")
knitr::opts_chunk$set(echo = TRUE)
workingDir <- "C:/Users/sergi/Desktop/Code/Neurocomputacion/Actividad_3"
setwd(workingDir)
datos <- read.table(file=paste(workingDir,"datos_icb.txt",sep="/"), header=T, sep=" ", dec=".")
library(rminer)
library(nnet)
fit <- nnet((recid=="SI") ~ ., data = datos, size=neu,maxit=10000, decay=0.001)
library(nnet)
fit <- nnet((recid=="SI") ~ ., data = datos, size=2,maxit=10000, decay=0.001)
repHOut_ANN <- function(x, n, esq_val, neu){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
train <- x[ho$tr,]
test <- x[ho$ts,]
fit <- nnet((recid=="SI") ~ edad+tam+grado+gang+quim+horm, data = train, size=neu,maxit=10000, decay=0.001)
predicted.tr <- predict(fit, newdata=train, type="raw")
predicted.ts <- predict(fit, newdata=test, type="raw")
predicted_class.tr <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts <- ifelse(predicted.ts>0.5, "SI","NO")
acc.tr <- c(acc.tr,sum(predicted_class.tr == train$recid)/length(train$recid))
acc.ts <- c(acc.ts,sum(predicted_class.ts == test$recid)/length(test$recid))
}
list(X_acc.tr = mean(acc.tr), X_acc.ts = mean(acc.ts))
}
result <- sapply(c(1:15), repHOut, x = datos, n = 30, esq_val = 2/3)
result <- sapply(c(1:15), repHOut_ANN, x = datos, n = 30, esq_val = 2/3)
View(result)
result_ANN <- sapply(c(1:15), repHOut_ANN, x = datos, n = 30, esq_val = 2/3)
plot(unlist(result_ANN[1, ]), col="red", ylab="ACC", xlab="Nhh")
lines(unlist(result_ANN[2, ], col="blue"))
plot(unlist(result_ANN[1, ]), col="red", ylab="ACC", xlab="Nhh")
lines(unlist(result_ANN[2, ]), col="blue")
legend(legend = c("Test", "Training"),col=c("blue", "red"))
plot(unlist(result_ANN[1, ]), col="red", ylab="ACC", xlab="Nhh",ylim = c(0.5,1))
lines(unlist(result_ANN[2, ]), col="blue")
legend(7, 0.80, legend = c("Test", "Training"),col=c("blue", "red"))
plot(unlist(result_ANN[1, ]), col="red", ylab="ACC", xlab="Nhh",ylim = c(0.75,1))
lines(unlist(result_ANN[2, ]), col="blue")
legend(7, 0.80, legend = c("Test", "Training"),col=c("blue", "red"))
plot(unlist(result_ANN[1, ]), col="red", ylab="ACC", xlab="Nhh",ylim = c(0.75,1))
lines(unlist(result_ANN[2, ]), col="blue")
legend(7, 0.90, legend = c("Test", "Training"),col=c("blue", "red"))
plot(unlist(result_ANN[1, ]), col="red", ylab="ACC", xlab="Nhh",ylim = c(0.75,1), type = "l")
lines(unlist(result_ANN[2, ]), col="blue")
legend(7, 0.90, legend = c("Test", "Training"),col=c("blue", "red"))
View(result_ANN)
knitr::opts_chunk$set(echo = TRUE)
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma, num){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
svm.train <- x[svm$tr,]
svm.test <- x[svm$ts,]
svm.fit <- svm(recid~., data = svm.train, cost=cost, gamma=gamma, probability = TRUE)
predicted.tr <- predict(fit, newdata=train, type="raw")
predicted.ts <- predict(fit, newdata=test, type="raw")
predicted_class.tr.svm <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts.svm <- ifelse(predicted.ts>0.5, "SI","NO")
svm.acc.tr <- c(svm.acc.tr,sum(predicted_class.tr == svm.train$recid)/length(svm.train$recid))
svm.acc.ts <- c(svm.acc.ts,sum(predicted_class.ts == svm.test$recid)/length(svm.test$recid))
}
list(X_acc.tr.svm = mean(svm.acc.tr), X_acc.ts.svm = mean(svm.acc.ts))
}
knitr::opts_chunk$set(echo = TRUE)
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, cost = datin$cost, gamma = datin$gamma)})
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = datin$cost, gamma = datin$gamma)})
library(rminer)
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma, num){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
svm.train <- x[svm$tr,]
svm.test <- x[svm$ts,]
svm.fit <- svm(recid~., data = svm.train, cost=cost, gamma=gamma, probability = TRUE)
predicted.tr <- predict(fit, newdata=train, type="raw")
predicted.ts <- predict(fit, newdata=test, type="raw")
predicted_class.tr.svm <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts.svm <- ifelse(predicted.ts>0.5, "SI","NO")
svm.acc.tr <- c(svm.acc.tr,sum(predicted_class.tr == svm.train$recid)/length(svm.train$recid))
svm.acc.ts <- c(svm.acc.ts,sum(predicted_class.ts == svm.test$recid)/length(svm.test$recid))
}
list(X_acc.tr.svm = mean(svm.acc.tr), X_acc.ts.svm = mean(svm.acc.ts))
}
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = datin$cost, gamma = datin$gamma)})
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma, num){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
svm.train <- x[ho$tr,]
svm.test <- x[ho$ts,]
svm.fit <- svm(recid~., data = svm.train, cost=cost, gamma=gamma, probability = TRUE)
predicted.tr <- predict(fit, newdata=train, type="raw")
predicted.ts <- predict(fit, newdata=test, type="raw")
predicted_class.tr.svm <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts.svm <- ifelse(predicted.ts>0.5, "SI","NO")
svm.acc.tr <- c(svm.acc.tr,sum(predicted_class.tr == svm.train$recid)/length(svm.train$recid))
svm.acc.ts <- c(svm.acc.ts,sum(predicted_class.ts == svm.test$recid)/length(svm.test$recid))
}
list(X_acc.tr.svm = mean(svm.acc.tr), X_acc.ts.svm = mean(svm.acc.ts))
}
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = datin$cost, gamma = datin$gamma)})
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma, num){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
svm.train <- x[ho$tr,]
svm.test <- x[ho$ts,]
svm.fit <- svm(as.factor(x$recid)~., data = svm.train, cost=cost, gamma=gamma, probability = TRUE)
predicted.tr <- predict(fit, newdata=train, type="raw")
predicted.ts <- predict(fit, newdata=test, type="raw")
predicted_class.tr.svm <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts.svm <- ifelse(predicted.ts>0.5, "SI","NO")
svm.acc.tr <- c(svm.acc.tr,sum(predicted_class.tr == svm.train$recid)/length(svm.train$recid))
svm.acc.ts <- c(svm.acc.ts,sum(predicted_class.ts == svm.test$recid)/length(svm.test$recid))
}
list(X_acc.tr.svm = mean(svm.acc.tr), X_acc.ts.svm = mean(svm.acc.ts))
}
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = datin$cost, gamma = datin$gamma)})
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma, num){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
svm.train <- x[ho$tr,]
svm.test <- x[ho$ts,]
svm.fit <- svm(as.factor(recid)~., data = svm.train, cost=cost, gamma=gamma, probability = TRUE)
predicted.tr <- predict(fit, newdata=train, type="raw")
predicted.ts <- predict(fit, newdata=test, type="raw")
predicted_class.tr.svm <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts.svm <- ifelse(predicted.ts>0.5, "SI","NO")
svm.acc.tr <- c(svm.acc.tr,sum(predicted_class.tr == svm.train$recid)/length(svm.train$recid))
svm.acc.ts <- c(svm.acc.ts,sum(predicted_class.ts == svm.test$recid)/length(svm.test$recid))
}
list(X_acc.tr.svm = mean(svm.acc.tr), X_acc.ts.svm = mean(svm.acc.ts))
}
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = datin$cost, gamma = datin$gamma)})
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma, num){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
svm.train <- x[ho$tr,]
svm.test <- x[ho$ts,]
svm.fit <- svm(as.factor(recid)~., data = svm.train, cost=cost, gamma=gamma, probability = TRUE)
predicted.tr <- predict(svm.fit, newdata=svm.train, type="raw")
predicted.ts <- predict(svm.fit, newdata=svm.test, type="raw")
predicted_class.tr.svm <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts.svm <- ifelse(predicted.ts>0.5, "SI","NO")
svm.acc.tr <- c(svm.acc.tr,sum(predicted_class.tr == svm.train$recid)/length(svm.train$recid))
svm.acc.ts <- c(svm.acc.ts,sum(predicted_class.ts == svm.test$recid)/length(svm.test$recid))
}
list(X_acc.tr.svm = mean(svm.acc.tr), X_acc.ts.svm = mean(svm.acc.ts))
}
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = datin$cost, gamma = datin$gamma)})
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma, num){
svm.acc.tr <- c()
svm.acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
svm.train <- x[ho$tr,]
svm.test <- x[ho$ts,]
svm.fit <- svm(as.factor(recid)~., data = svm.train, cost=cost, gamma=gamma, probability = TRUE)
predicted.tr <- predict(svm.fit, newdata=svm.train, type="raw")
predicted.ts <- predict(svm.fit, newdata=svm.test, type="raw")
predicted_class.tr.svm <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts.svm <- ifelse(predicted.ts>0.5, "SI","NO")
svm.acc.tr <- c(svm.acc.tr,sum(predicted_class.tr == svm.train$recid)/length(svm.train$recid))
svm.acc.ts <- c(svm.acc.ts,sum(predicted_class.ts == svm.test$recid)/length(svm.test$recid))
}
list(X_acc.tr.svm = mean(svm.acc.tr), X_acc.ts.svm = mean(svm.acc.ts))
}
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = datin$cost, gamma = datin$gamma)})
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma, num){
svm.acc.tr <- c()
svm.acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
svm.train <- x[ho$tr,]
svm.test <- x[ho$ts,]
svm.fit <- svm(as.factor(recid)~., data = svm.train, cost=cost, gamma=gamma, probability = TRUE)
predicted.tr <- predict(svm.fit, newdata=svm.train, type="raw")
predicted.ts <- predict(svm.fit, newdata=svm.test, type="raw")
predicted_class.tr.svm <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts.svm <- ifelse(predicted.ts>0.5, "SI","NO")
svm.acc.tr <- c(svm.acc.tr,sum(predicted_class.tr.svm == svm.train$recid)/length(svm.train$recid))
svm.acc.ts <- c(svm.acc.ts,sum(predicted_class.ts.svm == svm.test$recid)/length(svm.test$recid))
}
list(X_acc.tr.svm = mean(svm.acc.tr), X_acc.ts.svm = mean(svm.acc.ts))
}
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = datin$cost, gamma = datin$gamma)})
View(svm.res)
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma, num){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
train <- x[ho$tr,]
test <- x[ho$ts,]
svm.fit <- svm(recid ~ ., data = train, cost = cost, gamma = gamma, probability = TRUE)
predicted.tr <- predict(svm.fit, newdata=train, type="raw")
predicted.ts <- predict(svm.fit, newdata=test, type="raw")
predicted_class.tr <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts <- ifelse(predicted.ts>0.5, "SI","NO")
acc.tr <- c(acc.tr,sum(predicted_class.tr == train$recid)/length(train$recid))
acc.ts <- c(acc.ts,sum(predicted_class.ts == test$recid)/length(test$recid))
}
list(X_acc.tr = mean(acc.tr), X_acc.ts = mean(acc.ts))
}
repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = 1000, gamma = 1)
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
train <- x[ho$tr,]
test <- x[ho$ts,]
svm.fit <- svm(recid ~ ., data = train, cost = cost, gamma = gamma, probability = TRUE)
predicted.tr <- predict(svm.fit, newdata=train, type="raw")
predicted.ts <- predict(svm.fit, newdata=test, type="raw")
predicted_class.tr <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts <- ifelse(predicted.ts>0.5, "SI","NO")
acc.tr <- c(acc.tr,sum(predicted_class.tr == train$recid)/length(train$recid))
acc.ts <- c(acc.ts,sum(predicted_class.ts == test$recid)/length(test$recid))
}
list(X_acc.tr = mean(acc.tr), X_acc.ts = mean(acc.ts))
}
repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = 1000, gamma = 1)
library(e1071)
library(rminer)
workingDir <- "C:/Users/sergi/Desktop/Code/Neurocomputacion/Actividad_3"
setwd(workingDir)
datos <- read.table(file=paste(workingDir,"datos_icb.txt",sep="/"), header=T, sep=" ", dec=".")
acc.tr <- c()
acc.ts <- c()
ho <- holdout(datos$recid, ratio = 2/3)
train <- x[ho$tr,]
test <- x[ho$ts,]
ho <- holdout(datos$recid, ratio = 2/3)
train <- datos[ho$tr,]
test <- datos[ho$ts,]
svm.fit <- svm(recid ~ ., data = train, cost = 1000, gamma = 2, probability = TRUE)
svm.fit <- svm(as.factor(recid) ~ ., data = train, cost = 1000, gamma = 2, probability = TRUE)
predicted.tr <- predict(svm.fit, newdata=train, type="raw")
predicted.ts <- predict(svm.fit, newdata=test, type="raw")
predicted_class.tr <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts <- ifelse(predicted.ts>0.5, "SI","NO")
predicted.tr <- predict(svm.fit, newdata=train, probability = TRUE)
predicted.ts <- predict(svm.fit, newdata=test, probability = TRUE)
library(e1071)
library(rminer)
workingDir <- "C:/Users/sergi/Desktop/Code/Neurocomputacion/Actividad_3"
setwd(workingDir)
datos <- read.table(file=paste(workingDir,"datos_icb.txt",sep="/"), header=T, sep=" ", dec=".")
acc.tr <- c()
acc.ts <- c()
ho <- holdout(datos$recid, ratio = 2/3)
train <- datos[ho$tr,]
test <- datos[ho$ts,]
svm.fit <- svm(as.factor(recid) ~ ., data = train, cost = 1000, gamma = 2, probability = TRUE)
predicted.tr <- predict(svm.fit, newdata=train, probability = TRUE)
pred.tr <- attr(predict(svm.fit, newdata = train, probability=TRUE), "probabilities")[,"SI"]
pred.ts <- attr(predict(svm.fit, newdata = test, probability=TRUE), "probabilities")[,"SI"]
predicted_class.tr <- ifelse(predicted.tr>0.5, "SI","NO")
predicted_class.ts <- ifelse(predicted.ts>0.5, "SI","NO")
predicted_class.tr <- ifelse(pred.tr>0.5, "SI","NO")
predicted_class.ts <- ifelse(pred.ts>0.5, "SI","NO")
acc.tr <- c(acc.tr,sum(predicted_class.tr == train$recid)/length(train$recid))
acc.ts <- c(acc.ts,sum(predicted_class.ts == test$recid)/length(test$recid))
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
train <- x[ho$tr,]
test <- x[ho$ts,]
svm.fit <- svm(recid ~ ., data = train, cost = cost, gamma = gamma, probability = TRUE)
pred.tr <- attr(predict(svm.fit, newdata = train, probability=TRUE), "probabilities")[,"SI"]
pred.ts <- attr(predict(svm.fit, newdata = test, probability=TRUE), "probabilities")[,"SI"]
predicted_class.tr <- ifelse(pred.tr>0.5, "SI","NO")
predicted_class.ts <- ifelse(pred.ts>0.5, "SI","NO")
acc.tr <- c(acc.tr,sum(predicted_class.tr == train$recid)/length(train$recid))
acc.ts <- c(acc.ts,sum(predicted_class.ts == test$recid)/length(test$recid))
}
list(X_acc.tr = mean(acc.tr), X_acc.ts = mean(acc.ts))
}
repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = 1000, gamma = 1)
library(e1071)
repHOut_SVM <- function(x, n, esq_val, cost, gamma){
acc.tr <- c()
acc.ts <- c()
for (i in 1:n){
ho <- holdout(x$recid, ratio = esq_val)
train <- x[ho$tr,]
test <- x[ho$ts,]
svm.fit <- svm(as.factor(recid) ~ ., data = train, cost = cost, gamma = gamma, probability = TRUE)
pred.tr <- attr(predict(svm.fit, newdata = train, probability=TRUE), "probabilities")[,"SI"]
pred.ts <- attr(predict(svm.fit, newdata = test, probability=TRUE), "probabilities")[,"SI"]
predicted_class.tr <- ifelse(pred.tr>0.5, "SI","NO")
predicted_class.ts <- ifelse(pred.ts>0.5, "SI","NO")
acc.tr <- c(acc.tr,sum(predicted_class.tr == train$recid)/length(train$recid))
acc.ts <- c(acc.ts,sum(predicted_class.ts == test$recid)/length(test$recid))
}
list(X_acc.tr = mean(acc.tr), X_acc.ts = mean(acc.ts))
}
repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = 1000, gamma = 1)
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
result_SVM <- sapply(c(1:15), repHOut_ANN, x = datos, n = 30, esq_val = 2/3)
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
datin <- expand.grid(gamma = gamma, cost = cost)
#result_SVM <- sapply(c(1:15), repHOut_, x = datos, n = 30, esq_val = 2/3)
svm.res <- sapply(1:nrow(datin), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = datin$cost, gamma = datin$gamma)})
View(svm.res)
View(datin)
install.packages('plotly')
gamma <- c(0.01, 0.05, 0.1, 0.25, 0.5, 1)
cost <- c(1, 10, 100, 1000)
GC <- expand.grid(gamma = gamma, cost = cost)
result.svm <- sapply(1:nrow(GC), function(j){repHOut_SVM(datos, n = 30, esq_val = 2/3, cost = GC$cost, gamma = GC$gamma)})
library(plotly)
GC$acc.tr <- unlist(result.svm[1,])
GC$acc.ts <- unlist(result.svm[2,])
plot_ly(GC, x = ~cost, y = ~gamma, z = ~acc.ts, color = ~acc.ts)
