{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "ExamplePytorchCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c74523e74ff4aee85fde72defce04b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_278cd7e8919244b48ea1603ffcf2b6bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff026e445375477788fe3a58aed90683",
              "IPY_MODEL_a16517cc7e91445081dad108e7a200af"
            ]
          }
        },
        "278cd7e8919244b48ea1603ffcf2b6bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff026e445375477788fe3a58aed90683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_09cb1851881d4750b4841456f4015f99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4aeb575d6e64a8a91c6b5c6a3d3180d"
          }
        },
        "a16517cc7e91445081dad108e7a200af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff049abf4be24295bb0097635d48092c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:09&lt;00:00, 18363610.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b9b74aae75840d8bb7864db45150bd1"
          }
        },
        "09cb1851881d4750b4841456f4015f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4aeb575d6e64a8a91c6b5c6a3d3180d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff049abf4be24295bb0097635d48092c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b9b74aae75840d8bb7864db45150bd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UesLq2Mod_xF"
      },
      "source": [
        "# **Example of Convolutional Neural Networks with Pytorch**\n",
        "From the book Deep Learning with Pytorch, chapter 8\n",
        "\n",
        "In order to run this example more quickly in Google Colab, you must activate the GPU, by choosing Runtime -> Change runtime type -> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcvLzoILeVGA"
      },
      "source": [
        "\n",
        "Load the matplotlib library and set the graphics to be plotted within the Jupyter notebook\n",
        "\n",
        "Also load the PyTorch library, and fix the random seed to ensure the reproducibility of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVA-sS5xd6ra",
        "outputId": "77ae97ed-da48-446c-d906-9c7b77cf39cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9aa07d85a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tleFbSpgfZzF"
      },
      "source": [
        "Establish the 10 classes that are available in the CIFAR10 dataset, see https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhQpLYJYd6re"
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ireg983Qfp_q"
      },
      "source": [
        "Download the training data for the CIFAR10 dataset, upzip it to the virtual \n",
        "folder ../data-unversioned/p1ch6/ and store it as the `cifar10` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alkUMvOXd6ri",
        "outputId": "b0320894-09c7-4c78-e846-990a83e5b2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "8c74523e74ff4aee85fde72defce04b4",
            "278cd7e8919244b48ea1603ffcf2b6bb",
            "ff026e445375477788fe3a58aed90683",
            "a16517cc7e91445081dad108e7a200af",
            "09cb1851881d4750b4841456f4015f99",
            "b4aeb575d6e64a8a91c6b5c6a3d3180d",
            "ff049abf4be24295bb0097635d48092c",
            "0b9b74aae75840d8bb7864db45150bd1"
          ]
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c74523e74ff4aee85fde72defce04b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data-unversioned/p1ch6/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H59KggYXgXDl"
      },
      "source": [
        "Download the validation data for the CIFAR10 dataset, upzip it to the virtual \n",
        "folder ../data-unversioned/p1ch6/ and store it as the `cifar10_val` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld-Qegk6d6rl",
        "outputId": "35ea3e50-ebcc-47f2-e8d5-f3e1de51655a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTi0SOX4gri6"
      },
      "source": [
        "Select the classes that the CNN will classify, namely the airplane (index 0) and bird (index 2) classes\n",
        "\n",
        "Then extract a subset of the full training CIFAR10 dataset which contains the training samples of those two classes into the `cifar2` variable, and a subset of the full validation CIFAR10 dataset with the validation samples of these two classes into the `cifar2_val` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpqc4xl2d6ro",
        "outputId": "e3790c8e-145b-4e57-9957-cdf3e23b7b98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10\n",
        "          if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 2]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IxxfxrkhqT0"
      },
      "source": [
        "Create a fully connected model with four linear layers and three hyperbolic tangent layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpfdDZNCd6rr"
      },
      "source": [
        "connected_model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puINVGEYhxGK"
      },
      "source": [
        "Print out the overall number of parameters of the fully connected model, and the number of parameters per layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhPGov2Ad6ru",
        "outputId": "9ebc04ca-1838-470b-c430-4ac8e4369378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numel_list = [p.numel()\n",
        "              for p in connected_model.parameters()\n",
        "              if p.requires_grad == True]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjZblGmjiGKH"
      },
      "source": [
        "Create a `first_model` model with two linear layers, a hyperbolic tangent layer, and a soft max layer at the end to yield the classification result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usAY777md6ry"
      },
      "source": [
        "first_model = nn.Sequential(\n",
        "                nn.Linear(3072, 512),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(512, 2),\n",
        "                nn.LogSoftmax(dim=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yktLmOZviQws"
      },
      "source": [
        "Print out the overall number of parameters of the `first_model` model, and the number of parameters per layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvotVLgbd6r1",
        "outputId": "9293d865-f282-4664-9c96-efdbdd8df894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numel_list = [p.numel() for p in first_model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1574402, [1572864, 512, 1024, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pIl7y__jmoP"
      },
      "source": [
        "Create a linear layer with 3072 input features and 1024 output features\n",
        "\n",
        "Then print out the number of synaptic weights and the number of biases of the linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X3TN7SVd6r3",
        "outputId": "a5f59686-580e-471c-81fa-23260cd46f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "linear = nn.Linear(3072, 1024)\n",
        "\n",
        "linear.weight.shape, linear.bias.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1024, 3072]), torch.Size([1024]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idWY3Ghlj35S"
      },
      "source": [
        "Create a two dimensional convolutional layer with 3 input channels, 16 output channels, and kernel size 3. The stride is left to the default value, which is 1. See page 197 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBKBgHLzd6r5",
        "outputId": "feee6ce4-72be-4cdc-dce9-aa715b56ebd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "conv = nn.Conv2d(3, 16, kernel_size=3) # <1>\n",
        "conv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb-JEPmukLDz"
      },
      "source": [
        "Print out the number of synaptic weights and the number of biases of the convolutional layer. See page 197 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP5hU2tVd6r7",
        "outputId": "39efd14c-90e3-4a49-89ad-b46d89874a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "conv.weight.shape, conv.bias.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l5tJkQQkY6D"
      },
      "source": [
        "Extract the first training image (index 0) from the `cifar2` variable to the `img` variable\n",
        "\n",
        "Then apply the convolutional layer to the image and put the result into the `output` variable\n",
        "\n",
        "See page 198 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s-VvX0hd6r9",
        "outputId": "c8e6c83f-7c4c-4fc5-9ad1-17f59d15fe2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img, _ = cifar2[0]\n",
        "output = conv(img.unsqueeze(0))\n",
        "img.unsqueeze(0).shape, output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQD2D-qfky-0"
      },
      "source": [
        "Show the first training image\n",
        "\n",
        "Then show the same image, converted to grayscale\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaGDFr3-d6r_",
        "outputId": "a6116fd1-03d9-4cd8-b422-1a5ff0a21155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "plt.imshow(np.transpose(img,(1, 2, 0)))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(img.mean(0), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb9nXv-gq4iT",
        "outputId": "cbcefead-d0bc-458e-e85c-42baea017d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output[0,0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfhZSR6vqoh1"
      },
      "source": [
        "Show the first channel of the output of the convolutional layer to the left\n",
        "\n",
        "Then show the input (converted to grayscale) to the convolutional layer to the right\n",
        "\n",
        "Please note that the output is two pixels smaller than the input, due to the lack of padding in the convolutional layer\n",
        "\n",
        "See page 198 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k9DDW_id6sB",
        "outputId": "09e62849-204b-4a01-cee5-23a5db2bc46e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "plt.figure(figsize=(10, 4.8))  # bookskip\n",
        "ax1 = plt.subplot(1, 2, 1)   # bookskip\n",
        "plt.title('output')   # bookskip\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)  # bookskip\n",
        "plt.imshow(img.mean(0), cmap='gray')  # bookskip\n",
        "plt.title('input')  # bookskip\n",
        "plt.savefig('Ch8_F2_PyTorch.png')  # bookskip\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAEtCAYAAADHtl7HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de4xc533e8efH5WW5Sy6Xu7wtL+JFpKkbTUmgHctWjdSxXSdIYrsI7BhBqgJO5BZx0QAxAtdpG6dIASdobARom0KpXCupE9tJnNpJjTbyVVDSOKJCUZJFSpTIpXjd5fK+vO/y7R87DFYy5/fw7NnLUPx+AEHLeXhm3jlzzjsvZ2eeiVKKAAAAcONmzfQAAAAAbjYsoAAAACpiAQUAAFARCygAAICKWEABAABUxAIKAACgIhZQAIBbQkT8ICJ+dKbHgTeGoAcKUyEiiqRNpZSXW/H6AGAqRMQXJB0spfzbmR4LphavQAEAAFTEAgqpiLgzIr4bEacaL3//dOPy70bEL4z7e/88Ip5s/PxE4+KdETEcER+OiB+NiIMR8amIGIqI/oj4uXHbV7q+qb7fAN54GvPOuyPi0xHxlYj4g4g425jbtr3u7/2biHghIk5GxP+IiPZG9g9z07i/XyJiY0Q8LOnnJP1qY676i+m9h5hOLKDQVETMkfQXkv5K0jJJ/0rSFyNic7ZdKeWdjR+3llIWlFK+3PjzCklLJK2S9JCkR9x1mesDgIn6aUlfktQt6euS/vPr8p+T9E8k3S7pTZLsr+RKKY9I+qKk327MVT81qSNGS2EBhczbJC2Q9JlSyuVSyrcl/aWkj9S4zn9XSrlUSvmepP8t6UOTME4AqOrJUso3Simjkv5Q0tbX5f+5lHKglHJC0n9UvXkPb0AsoJBZKelAKeXquMv2a+wVpIk4WUo597rrWjnRwQFADUfH/XxeUntEzB532YFxPzNX4YewgELmsKQ1ETH+OLlN0iFJ5yR1jLt8xQ1c3+KI6HzddR1u/DyR6wOAqbJm3M9N56qIeP1cxUfbbxEsoJD5vsb+ZfarETGn0Z/yUxp738Azkv5pRHRExEZJH33dtgOSNlznOn8jIuZGxD+S9JOS/qRx+USvDwCmwi9FxOqI6JH0a5Kuvfdyp6S7I+LexhvLP/267ZirbhEsoNBUKeWyxhZMPy5pSNJ/lfTPSim7JX1O0mWNTRaPaeyNk+N9WtJjjU/vXXuf01FJJzX2L7kvSvoXjevSBK8PAKbKH2nsAzR7Jb0i6TclqZTykqT/IOmbkvZIevJ12z0q6a7GXPW/pm+4mG4UaWJaNF69+p+llNUzPRYAyEREv6RfKKV8c6bHgtbFK1AAAAAVsYACAACoiF/hAQAAVMQrUAAAABWxgAIAAKhotv8rzUXE+yT9rqQ2Sf+9lPKZ7O93dnaW7u7upvm8efPS2xsZGUnzS5cupbn7dWVbW1ut7bPcbTt7dv5QzJqVr3Xr3reIqJU7dX9VfPXq1Vq5O3YuX76c5vPnz2+auX3rjkv32Lp9727fcde/fPnyWtf/9NNPD5VSlta6kilSZQ7r6uoq2b44c+ZMeltz585N87qPo9ve3X42B82ZMyfd1h3jFy5cSHM39rr7ZnR0NM3dOVh3/nXzk9u/7vYdN/9l+2eq3+bj5t66c7vjth8aGmo6f014ARURbZL+i6T3SDoo6amI+Hop5YVm23R3d+tjH/tY0+vcsCHvHjt+/Hia79+/P82vXLmS5gsXLkxz90BnuTsIent707y9vT3N3UGQLVwlv3h1T7LuBHcTmMsvXryY5ufOnUvzEydOpHl/f3+a33PPPU2zRYsWpdu+8sorab5gwYI0d4trd/t1J+9PfOITae5ERH5izpCqc9jy5cv12c9+tun1ffvb305vb9Wq/BuQ3OPojgM3f7nbzxaHS5fm6999+/al+bPPPpvm7r67+cvNT6dOnUrzjo6ONM/+ASX5+dctIFeuzL8lprOzM83d7bv7f/LkyaZZ3bnbOXToUJoPDw+nuVsXuAXgsWPH0vzRRx9tOn/VWda+VdLLpZS9jcLFL0l6f43rA4DpxBwGYMLqLKBW6bVftnhQE/+SWQCYbsxhACZsyt9EHhEPR8T2iNjufs0CAK1k/Px1+vTpmR4OgBZSZwF1SK/9turVjcteo5TySCllWyllm/s9LgBMIzuHjZ+/3Pt0ANxa6iygnpK0KSLWR8RcST8r6euTMywAmHLMYQAmbMKfwiuljETExyX9X419BPjzpZQfTNrIAGAKMYcBqKNWD1Qp5RuSvnGjf7+9vV133nln09x91NN9VNV9jPfo0aNp7j7u2NfXl+bZR0GHhoYmvK0kLVu2LM3dR+HrdsS4mgPXgXPgwIE0d7fvHhtXUeE+Cus+ypp91L+np6fWbbuKBvcRaldT4Oo3XEXGG1mVOSwi0uPAPU7f+9730nzLli1p3tXVlebuOHPvQT1//nzTzJ1frubgrrvuSnM3/7ncnQOuAsI9t7jnJncOuecOd+zU7elzNQd79+5tmrnnFjd3uxoX97ztjmunbodghiZyAACAilhAAQAAVMQCCgAAoCIWUAAAABWxgAIAAKiIBRQAAEBFLKAAAAAqqtUDVdXo6GjaF7Rnz550e9djsm7dujSfNStfL7quJNfFlHUVua4J1wPiekw6Ojpq5a7HxPWgHDr0Q9/i8xqug8v1pDinTp1Kc9dTdfbs2TTPHj/XkXPp0qU0r9vx4nqeXE8LX1FyYy5duqRXX321ab5hw4Z0++7u7jRfv359mrs5ZNeuXWn+wgsvpPmmTZuaZu57AF2Xjzu/6vYYufG5rjbXc+e2dz1Ybg5w989x8/Px48fTfOfOnU2z5cuXp9u+6U1vSnP3FW6u48vdN/e8fuTIkVrXn972hLcEAAC4RbGAAgAAqIgFFAAAQEUsoAAAACpiAQUAAFARCygAAICKWEABAABUNK09UCMjIzpx4kTT3PU5rFq1Ks0XL16c5q6HxfVRZD1PUj7+ixcvptuuXLkyzV2XhusCch1X58+fT/Njx46lefa4Sn78rqvI9ai4jpvBwcE0Hx4eTvPDhw83zdzYXAfOggUL0tz1TLmOMNfz5PY9xly8eFG7d+9umm/evDndfsuWLWmeXbfku8xc15ub3/72b/+2adbV1ZVu644xN3e+9NJLae6OcdfD5Dq03P1zzz1u/nzxxRfT3D03ufG5HkF3bGQ9WitWrEi3dXP76Ohomrt+xzlz5qT50NBQmtftIMvwChQAAEBFLKAAAAAqYgEFAABQEQsoAACAilhAAQAAVMQCCgAAoCIWUAAAABVNaw/UnDlz0k6JkZGRdHvXl+O6iFxPVHt7e5q7LpElS5Y0zVzPkOtxcj0gritoYGAgzV1Xh+uxqtvz5O7/oUOH0nznzp1p7o4N1/OSbd/T05Nu63J33Dmu42XevHlp7jrCMObKlSs6ePBg09z11biuINdX487BNWvWpPl9992X5tk55sa+Y8eONHfnt5ub3fZOb29vmrtz1M3frifP9WC55zbXkeiOHdfTlR077rFx9/3AgQNp7nr03HHv+s3c9bt9n+EVKAAAgIpYQAEAAFTEAgoAAKAiFlAAAAAVsYACAACoiAUUAABARSygAAAAKqrVAxUR/ZLOShqVNFJK2Zb9/ba2trQvqLu7O729M2fOpLnrwnBcn47r8pg9u/nudD0jQ0NDae46qLLblnyPiOsKch03rufJcV0d586dS3P32Nx9991pvnHjxjTv6+trmi1btizd1nFjd8f1/Pnza12/6xB7I6syh5VS0q4614fj+mxcH1h2DEr+HHc9UcePH2+auR411zPk5jfXNXTbbbeluetpcvOH6ypyPXfu9l3XkOu5cvPj448/nuZuDli4cGHTzN1399i6sbvj1p03EZHmrgOsjsko0vzHpZR8DwJA62IOA1AZv8IDAACoqO4Cqkj6q4h4OiIenowBAcA0Yg4DMCF1f4X3YCnlUEQsk/R4ROwupTwx/i80JqWHpfy74gBgBqRz2Pj5y73XDMCtpdYrUKWUQ43/D0r6c0lvvc7feaSUsq2Uss290RAAppObw8bPX+6DFgBuLRNeQEVEZ0QsvPazpPdKen6yBgYAU4k5DEAddX6Ft1zSnzc+Qjhb0h+VUv7PpIwKAKYecxiACZvwAqqUslfS1irbjI6Opp02WRfFte0zrqvIvYfh5MmTab5///40z3pc6vYouZ4n1zPieqhcz1TWESP5rg/Xc+Lun8vXrl2b5u9973vT3HWQbd68uWnmHrv+/v40P3/+fJrX3beu3yzrNnojqzqHRUTal+b6ajZs2JDm7jhxPXiuz+uBBx5I83e/+91NMzc3u54hN/8NDg6meVtbW5q7c+DIkSNp7jq21q9fn+ZdXV1p7uYId47v3r07zZ988sk0HxgYSPMVK1Y0zdx9c/1ibv6p23HoxnfhwoU0d/1rGWoMAAAAKmIBBQAAUBELKAAAgIpYQAEAAFTEAgoAAKAiFlAAAAAVsYACAACoqO534VXielRc10dnZ2eauy4S91UyLj9x4kSaZ10erudj2bJlae56nty+cz0srgvI7VvHjc85depUmmc9JpLvKnE9MlnHjtt3rl/M3bZ77OseO64nBWNGRkbSPjQ3fxw+fDjNXU+d64FyPVRPP/10mr/88stNM3ffXE/SqlWr0tydI7t27Upzt+/c/OCeW1xXm+sScl1GrifKdSC6x37dunVpnj0+bmy9vb1p7vrJ3NiHhobSvO78WacHj1egAAAAKmIBBQAAUBELKAAAgIpYQAEAAFTEAgoAAKAiFlAAAAAVTWuNQSml1sfB3Ufh3UdZr169mubd3d1pnlUwSKr1Eeeenp40dx/1PH36dJo7rmbBfdT97NmzaR4Rae4eO3f9S5cuTXN3bLmP2g4MDDTNZs3K/x3i9p37CHRXV1eauxoDd9y7j1jjxrj96Ko41q5dm+Zu/uvv70/zc+fOpXl2jh06dCjddnBwMM2XLFmS5u6j5osXL05zN3+4GpO6zx1u/sieGySpo6MjzV2Ngnv+eNe73pXm2WPvKijc8+KePXvS3J0Xrr7Dze3ueb1ORQ+vQAEAAFTEAgoAAKAiFlAAAAAVsYACAACoiAUUAABARSygAAAAKmIBBQAAUNG0FsDMmjUr7btwfTkLFy5Mc9fn4LqSXN+E6/vJemBcT8fcuXPT3PWAuH3nxu7uu8tPnjyZ5qOjo2nuuo7cY+86eI4cOZLmbv9kx5brsHE9JK4jzG3vOrbceVGnB+VWMjo6mh7n7hh0j7PraXJdQ3X7vLIuNddDNzw8nObuvm3ZsiXN+/r60tz1NLncPTbuHHE9dW7+cx1fBw4cSPPly5en+Y/8yI+kedYD6B57l7vnLrfvXM+Ue251+5YeKAAAgGnEAgoAAKAiFlAAAAAVsYACAACoiAUUAABARSygAAAAKmIBBQAAUJEtDomIz0v6SUmDpZR7Gpf1SPqypHWS+iV9qJSSFwFJmjNnjpYtW9Y0d10hrufEdW3U7auYM2dOmmddRq4ryPWouK4K13Xh9q27/WPHjqW561lxPU7t7e1pvnbt2jR3j83ly5fTfPHixWk+f/78NM+4jik3dqfuY1O3P6jVTdYcFhFpX5ubP06cOJHmp06dSvOsp0mSOjs709z17WTn6JIlS9JtDx8+nObuGB8ZGUlzN3Y3f7ievePHj6e5O0eGhobS3HUQuh6qo0ePpnlvb2+au+cHN0dlXE/T+vXr09zNva+++mqau33n5r869/1GtvyCpPe97rJPSvpWKWWTpG81/gwAregLYg4DMMnsAqqU8oSk1//T6f2SHmv8/JikD0zyuABgUjCHAZgKE33tankp5dp3YxyVlPfIA0BrYQ4DUEvtN5GXsTfnNH2DTkQ8HBHbI2K7+x0/AEy3bA4bP3+576IDcGuZ6AJqICL6JKnx/8Fmf7GU8kgpZVspZZv7UlQAmCY3NIeNn7/qvtkfwBvLRBdQX5f0UOPnhyR9bXKGAwDTgjkMQC12ARURfyzp/0naHBEHI+Kjkj4j6T0RsUfSuxt/BoCWwxwGYCrYAphSykeaRD82yWOxXRuuy8f1QLk+CNeV4XpWsi4Od92uI8b1rLgOmgsXLqS56ylx1+96SDZs2JDmbt/u2bMnzW+//fY0j4haedZDMzAwkG7rOrZcB47rKXEdNpcuXUrzFStWpPnNbjLnsGwOce+RcvvZHQd1+7zc+LLj2N2267lbs2ZNmq9evTrNV65cmeZufK6ryM2Prudp9+7dab5v3740d88PdR/7F198Mc2z+dcdt+6xcY+9u+9u/nSPnTvuXcdYhiZyAACAilhAAQAAVMQCCgAAoCIWUAAAABWxgAIAAKiIBRQAAEBFLKAAAAAqsj1Qk+nq1atpJ83FixfT7V0+d+7cNJ8/f36at7e3p/miRYvSPOtCcd8DeObMmTSv2/PkctcjsmrVqjR3XSHua3zc/Xc9WQ888ECau56ZnTt3pvnY16Vdn+tpcvvWdVCdO3cuzV2Pidve9Q9hTCkl7ZRx80tHR0eau64f9zi548h1rWVdR65L5/77709z19Pm5m7XZea+ZsftW9c1tGPHjjTv7+9Pc/fYueceN4e4Lib3/JHtP9cR6HqcXL5u3bo0X79+fZq7Hjy3bnDP6xlegQIAAKiIBRQAAEBFLKAAAAAqYgEFAABQEQsoAACAilhAAQAAVMQCCgAAoKJp7YEqpaR9RK6roy7X0+K6NpYtW5bmo6OjTbOsY0XyXRauR+rkyZNp7npUXE9T1oMk+Z6TY8eOpfnBgwfT3PVEuR6YefPmpbkbf3ZsuH3nOrLccen2TVdXV5rXfWwxpq2tTYsXL26aZz1w17bPuD4adw67Y9h1HWVdT67rzM3dbm51HVXu/Hbbu33juoLc9S9fvjzN3fjdObh9+/Y0f+c735nmGzZsSPPsucvNve65ze3by5cvp7nruMrGLvnnVtfBleEVKAAAgIpYQAEAAFTEAgoAAKAiFlAAAAAVsYACAACoiAUUAABARSygAAAAKprWHqi2tra068R1hbguEtf14bqUXB+F6zo5evRo02z37t3ptocOHUpz18Vx4sSJNM86XiTfEVO3i8g9tq7HynXouMfW3b7rEjl37lzTzHVMdXR0pLk7rlzueqZcf1nWzYbXyo4T19PkjmF3DNbtQnN9N9k54jquent703zhwoVp7rrQ3Pzi9q17brj77rvT/M4770zz8+fPp7mb33bs2JHmricqItJ848aNaf788883zdxj4+Ynt+/d/HPkyJE0d9z22fO2wytQAAAAFbGAAgAAqIgFFAAAQEUsoAAAACpiAQUAAFARCygAAICKWEABAABUZHugIuLzkn5S0mAp5Z7GZZ+W9IuSjjX+2qdKKd+wNzZ7tpYsWdI0dz0ormfF5cePH09z12fhelgOHDjQNDt8+HC67cWLF9PcdWk4rgPGdRm5fet6qFxHjbv/nZ2dtW7fdSU5WQ+W68hxHTVz585Nc9dhlZ1Tku/QeaP3QE3WHDY6Opr2gbmutbNnz6a5exzdOeC48WVdQ65HyPVAuR4kNzY3N7v5yfU0uX3rOgjdY+fmiGPHjqW5G5/bv/v27UvzbHyuw+v06dNp7uY3Z+/evWnu9o17bNxzX+ZGXoH6gqT3Xefyz5VS7m38ZxdPADBDviDmMACTzC6gSilPSMr/eQ8ALYo5DMBUqPMeqI9HxLMR8fmIWDxpIwKA6cEcBmDCJrqA+j1Jt0u6V9IRSb/T7C9GxMMRsT0itrv3qQDANLmhOWz8/FX3fYgA3lgmtIAqpQyUUkZLKVcl/b6ktyZ/95FSyrZSyraenp6JjhMAJs2NzmHj5y/3Zn4At5YJLaAiom/cHz8oqflXOQNAi2EOA1DXjdQY/LGkH5W0JCIOSvp1ST8aEfdKKpL6JX1sCscIABPGHAZgKtgFVCnlI9e5+NGJ3NjFixe1Z8+eprnrSXFdHpcvX07znTt3prnroVq0aFGaZ10kWX+M5HtGXJdPR0dHmrv75nqiXE+Le2zmz5+f5u7XI27/uPvvHjvXdZL1pLh9GxFp7nqi3GPjzpu6+c1usuawzs5OveUtb2ma1+3zWrlyZZovXlzvfe79/f1pnvX5uC4d19PkOvhcj5PrKnPHsOsqcu9vc7l7bNz8nXUISn7+O3LkSJq7Hqhs/nM9TG5+6uvrS3PXEei4HqjNmzenuZv7MzSRAwAAVMQCCgAAoCIWUAAAABWxgAIAAKiIBRQAAEBFLKAAAAAqYgEFAABQ0bR+N8Hw8LD+5m/+pmlet4/G9axs3749zV0fz9ve9rY0X7duXdNs9+7d6bauS8N1VdTtCnLfU1h3fK6HyXXouC6lZcuWpbnrkXE9K1mXyPDwcLptb29vmrvj1u1b1zHmxuf2LcZ0dXXpPe95T9PcPU6ur8adI+4cdPNXNvdK0gsvvNA0cz1FrsvH9bS5Y7SUkuau58n12M2bN6/W9T/33HNpnvXISf7+uZ69gYGBNN+6dWuaDw4ONs127NiRbuvmj6VLl6b5+vXr09w9N7nbd9vX6aHiFSgAAICKWEABAABUxAIKAACgIhZQAAAAFbGAAgAAqIgFFAAAQEUsoAAAACqa1h6oy5cva+/evU3z0dHRdHvX1eH6dC5evJjmrqvjjjvuSPMVK1Y0zY4fP55uO3/+/DR3Y3M9R47b966nyXXc9PT0pLm7/8uXL0/zlStXpvmZM2fS3PVAZcded3d3um1XV1eau+PS9Zy4x8b1UNXtX7tVLFiwQA8++GDT3PXJXL16Nc1dF5DreXLHgTvO9u3b1zRzPU3uHLh8+XKauw6tVatWpbnrGnI9Tm7fuB4m1zXk5n83/7qeJ9chVqdnyz33PPXUU2m+ePHiNHdzszuv3PyVdVxJ0r333pvmGV6BAgAAqIgFFAAAQEUsoAAAACpiAQUAAFARCygAAICKWEABAABUxAIKAACgomntgRodHdW5c+ea5q7nxHE9Kq7PYu3atWm+efPmNM+6Ntx9cz0orgfJ9XyMjIykuRuf6+By43ddRO3t7Wm+cePGNHf7p24P19DQUNPMdbi4HhTXkeOu33WArV+/Ps3rnne3itmzZ6ePpet5cuegOw7q9kSdPHkyzZ977rmmmTs/3dy5c+fONHddP66nyXH77qWXXkrzU6dOpbnrMqp7bFy6dCnNXVfcyy+/nObZ/Oye99x9q/vcVLdjzHVo7dmzJ80zvAIFAABQEQsoAACAilhAAQAAVMQCCgAAoCIWUAAAABWxgAIAAKiIBRQAAEBFtgcqItZI+gNJyyUVSY+UUn43InokfVnSOkn9kj5USkmLRiJCc+fObZrPmlVvPee6fDZt2pTmb37zm9Pc9V1kXSArVqxIt+3r60tz1yV05cqVNO/p6UnzV199Nc1nz84PlTe96U1pnj3uku95WbJkSZo7hw4dSnPXc5PtX9eR5XqaXIdM3Z4o1yHjbv9mNpnzl5TPUa7Pxh3j7jhxj3PWsSdJZ8+eTfOsJ8r1sLmuHXf+1Zlbb+T63fzl9o3LXc+cu313/2+77bY0X7VqVZovWrQozbMeqRMnTqTb3nHHHWnu+hcPHz6c5u68cs8t7rnPnVeZG1mxjEj6lVLKXZLeJumXIuIuSZ+U9K1SyiZJ32r8GQBaCfMXgClhF1CllCOllL9v/HxW0i5JqyS9X9Jjjb/2mKQPTNUgAWAimL8ATJVKvzOLiHWS7pP0fUnLSylHGtFRjb1EDgAtifkLwGS64QVURCyQ9GeSfrmU8ppfSJexLxq67pcNRcTDEbE9Ira793IAwFSYjPnr2LFj0zBSADeLG1pARcQcjU0+XyylfLVx8UBE9DXyPkmD19u2lPJIKWVbKWWbe7MXAEy2yZq/li5dOj0DBnBTsAuoGHt7/qOSdpVSPjsu+rqkhxo/PyTpa5M/PACYOOYvAFPF1hhIeoekn5f0XEQ807jsU5I+I+krEfFRSfslfWhqhggAE8b8BWBK2AVUKeVJSc1KIn6syo3NmjXLdjVl5syZk+a9vb1p7ro4uru709z9CrKzs7NptnLlynRb1xM1NDSU5mNv42jO/fph7969tba///7703z//v1p7nR0dKT54OB1fwPzD1xP1vnz59M86yJxx5XriKnbE+U6wk6dOpXmR48eTfOb2WTOX1evXk2PE9fz5Hqa6uZO1vMk5cexm7fd+8P6+/vT3L0/1u1bN3+6+dFdv9t3p0+fTnP33OVy9/yxdevWND9w4ECaZ89dbt8MDw+nuesQc3O7u/4f/OAHae76HxcuXJjmGZrIAQAAKmIBBQAAUBELKAAAgIpYQAEAAFTEAgoAAKAiFlAAAAAVsYACAACo6EaKNCfV6Oho02zWrHw957pIXJeG68PZvXt3mq9duzbN582b1zQbK0Ru7urVq2l+8ODBNF+yZEmau9t3++aee+5Jc7fvXQ9JV1dXmp89ezbNX3zxxTR3PVAuz7iepxMnTqR53Y4Yd96428/OSbxWdp66rqEFCxakuXscXNeZ6wtzXW4f+lDzLlHXFfbCCy+k+erVq9PczX91e5zcfR8YGEhzNz9u2bIlzV1XnLt9N/62trY0dz13y5c3/y7tS5cupdu6jqply5alueuxcx1ifX19ae7WDYcPH07zDK9AAQAAVMQCCgAAoCIWUAAAABWxgAIAAKiIBRQAAEBFLKAAAAAqmtYag4hIP87pPqp64cKFNHcf9V+0aFGau4/SHjt2LM2zGgP3Ucxz586lufsYf3bbktTe3p7m7iPUCxcuTPMjR46k+dDQUJq7Goa9e/em+V//9V+nufsYsfuIeba9Oy47OzvT3H0E2z02vb29ae4+gl2nwgEAblXT3gMFADejq1ev6vLly01z18fluticuj14WdePlC+0t23blm67adOmNHf/CHCL+O9+97tp7jqwuru7a23v/vH99re/Pc137dqV5m7/3H777Wnuuphcj9Tp06ebZq4Hyh3Xrl9xxYoVae5e2HD3zY3fdWRl+BUeAABARSygAAAAKmIBBQAAUBELKAAAgIpYQAEAAFTEAgoAAKCiae+ByvWaBTwAAA5xSURBVD5q6z5O6PK2trY0f/DBB9Pc9fW4LqTs45juul0P0Zo1a9L8pZdeSvOTJ0/Wuv2enp40dx81ddfvPmrqupbcR2HdR11dj1Z27LmOK7fvXMeX63FyH1+fO3dumrt+M4wppaQft3fHsKs5cOeQ+yj+wMBAmj///PNp/tRTTzXN3DHkzk83d7uP4buP+bv50c3dWT2FJG3YsCHNXZebmyPWr1+f5iMjI2n+1a9+Nc3d47ds2bKmmZsbXcfh8PBwmrt94+o3+vr60txVZLh9m+EVKAAAgIpYQAEAAFTEAgoAAKAiFlAAAAAVsYACAACoiAUUAABARSygAAAAKrI9UBGxRtIfSFouqUh6pJTyuxHxaUm/KOlaicynSinfyK7L9ai4Hqfe3t40d10dLnfX78aXdZG4nhLXI+I6YPbs2ZPmruvH9aSUUtL8zJkzae56mNz45s+fn+abN29Oc9cT5Xpgsi4T13HjOnK6urrS3B07ruPF9Q+54/pmNpnzV0Sk+9L1QLlj2PXlvPjii2n+5JNPpnl7e3uaZ31i3/zmN9NtFy9enOZufpg9O38quu2229LcnYOuC8h1HWU9STdy/a5ryB0bO3bsSPMnnngizV3P1KZNm5pm7rhx9809r7p+sp07d6b5hz/84TRftWpVmp8+fTrNMzdSpDki6VdKKX8fEQslPR0Rjzeyz5VS/tOEbx0AphbzF4ApYRdQpZQjko40fj4bEbsk5Us6AGgBzF8Apkql90BFxDpJ90n6fuOij0fEsxHx+YjIX8MFgBnE/AVgMt3wAioiFkj6M0m/XEo5I+n3JN0u6V6N/Qvvd5ps93BEbI+I7e59PgAwFSZj/jp+/Pi0jRdA67uhBVREzNHY5PPFUspXJamUMlBKGS2lXJX0+5Leer1tSymPlFK2lVK2uTejAcBkm6z5y70ZFsCtxS6gIiIkPSppVynls+MuH/8VyB+UlL+VHgCmGfMXgKlyI5/Ce4ekn5f0XEQ807jsU5I+EhH3auyjwf2SPjYlIwSAiWP+AjAlbuRTeE9KiutEaWfKdW9s9mwtWbKkae76cBYtWpTmd999d5r39PSkeTY2yXedZF0kriPGdVS5jpisw0XyPUeuB8WN/9SpU2nuuK4id/9dF5J7/53bP1lPjTsuBwYG0nzlypVpvm7dujR3HTvu2LjrrrvS/GY2mfPXlStX0sfSPQ7OSy+9lObPPvtsmr/yyitp7rqUOjs7m2YnT55Mt3VdZ+fOnUvz5557Ls0ffPDBNHf7zj02bu7fsmVLmruevqGhoTQ/evRoreu/77770tzNURnXAXjw4ME0d88N7thx27/5zW9Oc/fcsnv37jRPr3vCWwIAANyiWEABAABUxAIKAACgIhZQAAAAFbGAAgAAqIgFFAAAQEUsoAAAACq6kSLNSTN37ty002bZsmXp9u6rYLIeE8l3HY2Ojqa566PYv39/06xuV8/Vq1fTfKxwuTnXNeS2dz1LfX19ae56pNxj53ponJGRkTR3XSdZD1RHR0e6rTuu3H13PSl1O65cBw7GjIyMaHBwsGl++PDhdHv3OB46dKjW9u44cl1D2fbu/F6wYEGau2PM9RQtXbo0zd19e/XVV9PczX8nTpyodfuug8v1WGXHneTnL7f/sufGuh17+/btS3N33N5///1p7p4b3HnpnnszvAIFAABQEQsoAACAilhAAQAAVMQCCgAAoCIWUAAAABWxgAIAAKiIBRQAAEBF09oDNXv27LSPwvVNuPz48eNp7rqIXNeS69q4cuVK08z1jLgui7a2tjR3HVXO6tWr0/zcuXNp7u6f6yJyXUmux+T06dNpfv78+TR3j3127Ll+Htc/VnffuH2/ePHiNHfjw5iRkRENDQ01zd3jWPdxcvNbd3d3mru+nqyPZ+vWrem2r7zySpofOHAgzd/ylrekeU9PT5qvXbs2zQcGBtLc9Ti5c9w9tm7+XrNmTZr39/enuZvf3BySPbe54/Kee+5J8yNHjqS5G5t7bpw1K38daHh4OM1dx1l62xPeEgAA4BbFAgoAAKAiFlAAAAAVsYACAACoiAUUAABARSygAAAAKmIBBQAAUNG09kC1tbVpwYIFTXPX9+C6iLIeJsn3qLiujhUrVqT58uXLm2YdHR0T3lbyPR+uy8d1cfT29qa560k6e/ZsmrsOLffYLFq0qNb1u54W1/OS3X933Lh9OzIyUit3/UOuP23+/PlpjjGXL19O+4zcMeb6brK5UZLuvPPOND9x4kSau3Mky8+cOZNu63rosv4sSXryySfT/I477khzdwy//e1vT3PXg+c6ttz85OaArINLkgYHB9N83759aV6nx8od1+65bfbsfJnR1dWV5q6/0XUAuvnRnXcZXoECAACoiAUUAABARSygAAAAKmIBBQAAUBELKAAAgIpYQAEAAFTEAgoAAKAi2wMVEe2SnpA0r/H3/7SU8usRsV7SlyT1Snpa0s+XUtLChe7ubn3wgx+sP2r8kHXr1s30EICWNFlzWFtbW9oH5HqeXJ+O68txXW+uL+fYsWNp3t/f3zRzXWeux2jhwoVp7jr83L5zPXdu+82bN6f5xYsX09z1XLmeLNcTtXXr1jRfuXJlmh86dCjNjx49muYZd9y+4x3vSHN33Lpjw3Ukuo4wd2xkbuQVqEuS3lVK2SrpXknvi4i3SfotSZ8rpWyUdFLSRyc8CgCYOsxhACadXUCVMcONP85p/FckvUvSnzYuf0zSB6ZkhABQA3MYgKlwQ++Bioi2iHhG0qCkxyW9IulUKeXad0wclLRqaoYIAPUwhwGYbDe0gCqljJZS7pW0WtJbJeVfTDRORDwcEdsjYrv7HTwATIWJzmHj5y/3fY8Abi2VPoVXSjkl6TuSHpDUHRHX3j22WtJ136VWSnmklLKtlLJt6dKltQYLAHVUncPGz1/ujdAAbi12ARURSyOiu/HzfEnvkbRLY5PQzzT+2kOSvjZVgwSAiWIOAzAVbI2BpD5Jj0VEm8YWXF8ppfxlRLwg6UsR8ZuSdkh6dArHCQATxRwGYNLZBVQp5VlJ913n8r0aey8BALSsyZrD2tra1NXV1TTPOqIk6cCBA7Vyx/XZDA8Pp3kppWk2a1b+ywrXE7V+/fo0dz1IHR0daT4wMJDm+/btS3P3/ra1a9emebbvJN+T5XqY2tvb03zNmjVpvnHjxjTPjp29e/em27pfbS9ZsiTN3XHpjmv33uoLFy6kuev4ytBEDgAAUBELKAAAgIpYQAEAAFTEAgoAAKAiFlAAAAAVsYACAACoiAUUAABAReH6Kyb1xiKOSdo/7qIlkoambQDVtfL4WnlsUmuPr5XHJr3xxre2lHLTf48T89eka+XxtfLYpNYeXyuPTZrE+WtaF1A/dOMR20sp22ZsAEYrj6+Vxya19vhaeWwS47tZtPp+YHwT18pjk1p7fK08Nmlyx8ev8AAAACpiAQUAAFDRTC+gHpnh23daeXytPDaptcfXymOTGN/NotX3A+ObuFYem9Ta42vlsUmTOL4ZfQ8UAADAzWimX4ECAAC46czIAioi3hcRL0bEyxHxyZkYQyYi+iPiuYh4JiK2t8B4Ph8RgxHx/LjLeiLi8YjY0/j/4hYb36cj4lBjHz4TET8xQ2NbExHfiYgXIuIHEfGvG5fP+P5LxtYq+649Iv4uInY2xvcbjcvXR8T3G+fvlyNi7kyMbyYxh1UaC/PXxMfWsvOXGV+r7L+pncNKKdP6n6Q2Sa9I2iBprqSdku6a7nGYMfZLWjLT4xg3nndKul/S8+Mu+21Jn2z8/ElJv9Vi4/u0pE+0wL7rk3R/4+eFkl6SdFcr7L9kbK2y70LSgsbPcyR9X9LbJH1F0s82Lv9vkv7lTI91mvcLc1i1sTB/TXxsLTt/mfG1yv6b0jlsJl6Bequkl0spe0splyV9SdL7Z2AcN41SyhOSTrzu4vdLeqzx82OSPjCtgxqnyfhaQinlSCnl7xs/n5W0S9IqtcD+S8bWEsqY4cYf5zT+K5LeJelPG5fP6LE3Q5jDKmD+mrhWnr/M+FrCVM9hM7GAWiXpwLg/H1QL7fCGIumvIuLpiHh4pgfTxPJSypHGz0clLZ/JwTTx8Yh4tvES+Yy9RH9NRKyTdJ/G/hXSUvvvdWOTWmTfRURbRDwjaVDS4xp75eVUKWWk8Vda8fydasxh9bXU+ddES5yD17Ty/CXdmnMYbyK/vgdLKfdL+nFJvxQR75zpAWXK2OuQrfZxyt+TdLukeyUdkfQ7MzmYiFgg6c8k/XIp5cz4bKb333XG1jL7rpQyWkq5V9Jqjb3ycsdMjQWV3DRz2Eyff020zDkotfb8Jd26c9hMLKAOSVoz7s+rG5e1jFLKocb/ByX9ucZ2eqsZiIg+SWr8f3CGx/MapZSBxoF7VdLvawb3YUTM0djJ/cVSylcbF7fE/rve2Fpp311TSjkl6TuSHpDUHRGzG1HLnb/TgDmsvpY4/5pppXOwleevZuNrpf13zVTMYTOxgHpK0qbGu+DnSvpZSV+fgXFcV0R0RsTCaz9Leq+k5/OtZsTXJT3U+PkhSV+bwbH8kGsnd8MHNUP7MCJC0qOSdpVSPjsumvH912xsLbTvlkZEd+Pn+ZLeo7H3OHxH0s80/lrLHXvTgDmsvhk//zItdA627PwlMYfN1Dvjf0Jj79Z/RdKvzcQYkrFt0NinanZK+kErjE/SH2vsZdArGvt97Ucl9Ur6lqQ9kr4pqafFxveHkp6T9KzGTva+GRrbgxp7eftZSc80/vuJVth/ydhaZd+9WdKOxjiel/TvG5dvkPR3kl6W9CeS5s3UsTdT/zGHVRoP89fEx9ay85cZX6vsvymdw2giBwAAqIg3kQMAAFTEAgoAAKAiFlAAAAAVsYACAACoiAUUAABARSygAAAAKmIBBQAAUBELKAAAgIr+P/+N24qq9WepAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x345.6 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyPNH2MIA3bH"
      },
      "source": [
        "Create a two dimensional convolutional layer with 3 input channels, 1 output channel, and kernel size 3. The stride is left to the default value, which is 1. The padding is set to 1\n",
        "\n",
        "Then apply the convolutional layer to the fisrt training image, and put the result in the `output` variable. Please note that this time the output is the same size as the input, due to the padding.\n",
        "\n",
        "See page 199 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqBl5pNpd6sD",
        "outputId": "10270e51-332f-4f57-bbbc-59ad9818296f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1) # <1>\n",
        "output = conv(img.unsqueeze(0))\n",
        "img.unsqueeze(0).shape, output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 1, 32, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO7Mwzx1BcHB"
      },
      "source": [
        "Set the biases of the convolutional layer to zero. Then set the synaptic weights of the convolutional layer to 1.0/9.0. This corresponds to an averaging convolutional filter of size 3 x 3 pixels. See page 200 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX2hlt2nd6sF"
      },
      "source": [
        "with torch.no_grad():\n",
        "    conv.bias.zero_()\n",
        "    \n",
        "with torch.no_grad():\n",
        "    conv.weight.fill_(1.0 / 9.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N65e83kVAVg6"
      },
      "source": [
        "Plot the output of the convolutional layer to the left and the input to the right. Please note that the output is the same size as the input, due to the padding in the convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpAcoslAd6sG",
        "outputId": "2b44a7c4-d912-4912-88ae-b71cc14ee58a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "output = conv(img.unsqueeze(0))\n",
        "plt.figure(figsize=(10, 4.8))  # bookskip\n",
        "ax1 = plt.subplot(1, 2, 1)   # bookskip\n",
        "plt.title('output')   # bookskip\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)  # bookskip\n",
        "plt.imshow(img.mean(0), cmap='gray')  # bookskip\n",
        "plt.title('input')  # bookskip\n",
        "plt.savefig('Ch8_F4_PyTorch.png')  # bookskip\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x345.6 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RMhpkuiCCkB"
      },
      "source": [
        "Set the synaptic weights of the convolutional layer to a vertical edge detection filter. The biases are set to zero. See pages 200-201 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otS-dFSpd6sJ"
      },
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0]])\n",
        "    conv.bias.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfTFQAnTDGva"
      },
      "source": [
        "Plot the output of the convolutional layer to the left, and the grayscale version of the input to the right.\n",
        "\n",
        "Please note that the vertical edges are detected by the convolutional layer. They are viewed as very dark or very bright pixels in the output image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMwHNXTgd6sL",
        "outputId": "7c202815-241f-4342-8cfc-8c61f8a82e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "output = conv(img.unsqueeze(0))\n",
        "plt.figure(figsize=(10, 4.8))  # bookskip\n",
        "ax1 = plt.subplot(1, 2, 1)   # bookskip\n",
        "plt.title('output')   # bookskip\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)  # bookskip\n",
        "plt.imshow(img.mean(0), cmap='gray')  # bookskip\n",
        "plt.title('input')  # bookskip\n",
        "plt.savefig('Ch8_F5_PyTorch.png')  # bookskip\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x345.6 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys6kdkx6g3V6"
      },
      "source": [
        "Create a two dimensional max pooling layer `pool` with a pooling window of size 2x2. Then the input image is processed by the `pool` layer. Please note that the output has half the size of the input image, due to the 2x2 pooling. See page 204 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aKPX5_Ed6sM",
        "outputId": "96ccc6de-1b0f-4e62-a2da-60c62ae38297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pool = nn.MaxPool2d(2)\n",
        "output = pool(img.unsqueeze(0))\n",
        "\n",
        "img.unsqueeze(0).shape, output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct73_iFShPbT"
      },
      "source": [
        "Create a model with several layers: first a two dimensional convolutional layer, then a hyperbolic tangent layer, then a two dimensional max pooling layer, and then the same again. Store it into the `model` variable. See page 205 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzIqS4Wsd6sO"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            # ...\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-IT3_8ihdYx"
      },
      "source": [
        "Create a model with the same structure as the previous model, but with three additional layers: a linear layer, a hyperbolic tangent layer, and a final linear layer. Store it into the `model` variable. See page 206 of the book.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kymPYU6bd6sQ"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            # ... <1>\n",
        "            nn.Linear(8 * 8 * 8, 32),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(32, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_yEhnprhtbV"
      },
      "source": [
        "Print out the total number of parameter of the model, and the number of parameters per layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slFzfRACd6sR",
        "outputId": "71f4f9cb-6fe3-4a69-818f-ab3e3baa7269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33Q1PujVibEi"
      },
      "source": [
        "The previous model does not work because we need something to flatten the output of the last max pooling layer to reshape it before the first linear layer. Please see page 207 of the book. If you uncomment the following line, you will get an error when you try to process an input image with the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "tags": [
          "raises-exception"
        ],
        "id": "0bw8X1RQd6sU"
      },
      "source": [
        "#model(img.unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVkmE5baizgT"
      },
      "source": [
        "Next, a subclass of the `nn.Module` class is defined. In order to do so, the constructor of the class (`__init__`) and the `forward` method are defined. This is the minimum necessary methods that must be defined (see pages 207-208 of the book). The reshape that was necessary earlier is done by the following line:\n",
        "\n",
        "`out = out.view(-1, 8 * 8 * 8)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2RNeaymd6sV"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
        "        out = self.act3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSYyw_jsmRUr"
      },
      "source": [
        "Create an instance of the `Net` subclass of the `nn.Module` class, and store the instance into the `model` variable. \n",
        "\n",
        "Print out the overall number of parameters of `model`, and the number of parameters of each of its layers.\n",
        "\n",
        "See page 210 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyLSy_ORd6sX",
        "outputId": "1d48549f-92af-47f7-f3b2-11b4b9f2c56b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = Net()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyYZ4MZsm-4D"
      },
      "source": [
        "Create a new version of the `Net` subclass of the `nn.Module` class. This time, the functional versions of the hyperbolic tangent layer (`torch.tanh`) and the two dimensional max pooling layer (`F.max_pool2d`) are employed. This is possible because the hyperbolic tangent and max pooling layers have no parameters.\n",
        "\n",
        "See pages 210-211 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ-xMFivd6sZ"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XvHE-Ymn8U7"
      },
      "source": [
        "Process the input image with the current version of the model. The model processes the image correctly and outputs a vector with two real numbers, which represent the scores of the two classes. See pages 211-212 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW1CdMhyd6sb",
        "outputId": "16b2f7db-4835-4f1c-d56f-6c21ec3a98a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = Net()\n",
        "model(img.unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0157,  0.1143]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19YtAsXIKyGM"
      },
      "source": [
        "Define a standalone function that implements a training loop for the previously defined model. It receives as arguments the number of epochs, the optimizer, the model, the loss function, and the loader of the training images (inputs) and training labels (outputs). See page 212 of the book.\n",
        "\n",
        "The progress of the training is printed out. The average loss per training sample is printed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uex-GXI1d6sc"
      },
      "source": [
        "import datetime  # <1>\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "            \n",
        "            outputs = model(imgs)  # <4>\n",
        "            \n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "            \n",
        "            loss.backward()  # <7>\n",
        "            \n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWdij80hL9z4"
      },
      "source": [
        "Create a data loader for the training samples associated to the `cifar2` variable. Then create an instance of our custom defined model. After that, create a optimizer based on stochastic gradient descent (SGD), and a cross-entropy loss function. Cross entropy is adequate for classification problems, including multiclass classification. Binary entropy can be employed for binary classification only.\n",
        "\n",
        "Finally, execute the training by calling the `training_loop` function. See page 213 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "876mZoHod6se",
        "outputId": "c76955ce-7078-46e3-da49-00bb71768542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 17:55:27.078881 Epoch 1, Training loss 0.5634812323530768\n",
            "2020-10-03 17:56:00.103509 Epoch 10, Training loss 0.3277595060266507\n",
            "2020-10-03 17:56:37.087113 Epoch 20, Training loss 0.3035030489324764\n",
            "2020-10-03 17:57:13.835663 Epoch 30, Training loss 0.2824554865717129\n",
            "2020-10-03 17:57:50.599682 Epoch 40, Training loss 0.261043845468266\n",
            "2020-10-03 17:58:26.998810 Epoch 50, Training loss 0.24096738822331096\n",
            "2020-10-03 17:59:03.601568 Epoch 60, Training loss 0.21990723030012885\n",
            "2020-10-03 17:59:42.002751 Epoch 70, Training loss 0.20366100905237683\n",
            "2020-10-03 18:00:21.502142 Epoch 80, Training loss 0.18935413122366948\n",
            "2020-10-03 18:01:00.062262 Epoch 90, Training loss 0.17276086364012616\n",
            "2020-10-03 18:01:38.761341 Epoch 100, Training loss 0.1613998900932871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08_HKggpNsUE"
      },
      "source": [
        "Next we are going to measure the accuracy of the trained classifier on the training and validation sets. See page 214 of the book.\n",
        "\n",
        "First, a data loader for the training set `train_loader` and another data loader for the validation set `val_loader` are created.\n",
        "\n",
        "The `validate` function is defined to count the number of correct and incorrect classifications, computed over the training and validation sets. Then the accuracies are printed out.\n",
        "\n",
        "Finally, the `validate` function is executed to compute the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E8iOj42d6sg",
        "outputId": "5b92bfd6-180a-4bec-fd1e-b87f9c7c7285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.93\n",
            "Accuracy val: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjlPctezOd3S"
      },
      "source": [
        "The trained model is saved to a file. See page 214 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hUFSZcYd6sh"
      },
      "source": [
        "torch.save(model.state_dict(), data_path + 'birds_vs_airplanes.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1h5k5KlOnvy"
      },
      "source": [
        "Next the saved model is loaded. See page 215 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFd554zod6sm",
        "outputId": "3d8b44a8-9f4c-4496-a423-af63eae65305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loaded_model = Net()  # <1>\n",
        "loaded_model.load_state_dict(torch.load(data_path\n",
        "                                        + 'birds_vs_airplanes.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZxqgQ2OOxS2"
      },
      "source": [
        "Check out whether the training is done on the CPU or the GPU. See page 215 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rlaKVWvd6sn",
        "outputId": "d232cd38-1a47-47de-bf26-f30a1faca639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device cuda.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAOXh3fPF2s"
      },
      "source": [
        "Redefine the `training_loop` function so that the data are moved to the GPU if one is available. See page 215 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HMrWUMNd6sp"
      },
      "source": [
        "import datetime\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTncT-ncPd9f"
      },
      "source": [
        "Execute the training again, this time with the data on the GPU if available. If a GPU is available, the training should be faster than before. See page 216 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZnvW14md6sq",
        "outputId": "28c6ac2e-1bc6-4f2e-9cad-a837f8f17304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = Net().to(device=device)  # <1>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 18:01:52.450758 Epoch 1, Training loss 0.5717794697755462\n",
            "2020-10-03 18:01:55.928444 Epoch 10, Training loss 0.32852893906414127\n",
            "2020-10-03 18:01:59.649477 Epoch 20, Training loss 0.29495166365508063\n",
            "2020-10-03 18:02:03.231366 Epoch 30, Training loss 0.2696891484936331\n",
            "2020-10-03 18:02:06.955153 Epoch 40, Training loss 0.24715986933298173\n",
            "2020-10-03 18:02:10.640782 Epoch 50, Training loss 0.22627683733678927\n",
            "2020-10-03 18:02:14.395084 Epoch 60, Training loss 0.20998757788140304\n",
            "2020-10-03 18:02:18.122614 Epoch 70, Training loss 0.1935278656566219\n",
            "2020-10-03 18:02:21.741315 Epoch 80, Training loss 0.17991850624798209\n",
            "2020-10-03 18:02:25.358279 Epoch 90, Training loss 0.16617709111161294\n",
            "2020-10-03 18:02:28.984232 Epoch 100, Training loss 0.1566371135176367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q96aRVDCP3I2"
      },
      "source": [
        "Redefine the `validate` function so that the data are moved to the GPU, if available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGIb2u-md6ss",
        "outputId": "a369fece-96fa-4ec9-9efd-a87038dab8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    accdict = {}\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "        accdict[name] = correct / total\n",
        "    return accdict\n",
        "\n",
        "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.93\n",
            "Accuracy val: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD-pxueNQGbL"
      },
      "source": [
        "Load a saved model to the GPU. PyTorch is explicitly instructed to load the model to the GPU, even if the model was saved from the CPU. See page 217 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol-o0MXrd6su",
        "outputId": "e9cddb0d-828c-4a8c-b465-b7e69894306e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loaded_model = Net().to(device=device)\n",
        "loaded_model.load_state_dict(torch.load(data_path\n",
        "                                        + 'birds_vs_airplanes.pt',\n",
        "                                        map_location=device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wZPy61JTIKv"
      },
      "source": [
        "Create a new sublass NetWidth of the nn.Module class which defines a model with more channels coming from the first convolution. See page 218 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHjDRkzd6sv"
      },
      "source": [
        "class NetWidth(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(16 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 16 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KR9iYyOTYKO"
      },
      "source": [
        "Train the newly defined model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTmwKN7fd6sx",
        "outputId": "d3bf9e38-4786-45c6-ce96-9624c349de0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = NetWidth().to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 18:02:29.694127 Epoch 1, Training loss 0.569658173117668\n",
            "2020-10-03 18:02:33.313754 Epoch 10, Training loss 0.32219793481431946\n",
            "2020-10-03 18:02:37.268091 Epoch 20, Training loss 0.2805888512331969\n",
            "2020-10-03 18:02:41.199511 Epoch 30, Training loss 0.24591600890182386\n",
            "2020-10-03 18:02:45.106859 Epoch 40, Training loss 0.21832924896174935\n",
            "2020-10-03 18:02:49.015188 Epoch 50, Training loss 0.19432437609715067\n",
            "2020-10-03 18:02:52.917829 Epoch 60, Training loss 0.17152156078132094\n",
            "2020-10-03 18:02:56.929907 Epoch 70, Training loss 0.14893593696082474\n",
            "2020-10-03 18:03:00.941066 Epoch 80, Training loss 0.1271450824466101\n",
            "2020-10-03 18:03:04.860362 Epoch 90, Training loss 0.10680842508745801\n",
            "2020-10-03 18:03:08.802123 Epoch 100, Training loss 0.08849463259480941\n",
            "Accuracy train: 0.96\n",
            "Accuracy val: 0.89\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 0.9629, 'val': 0.89}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3NIqWZaTchi"
      },
      "source": [
        "Redefine the `NetWidth` subclass by setting the number of channels (`n_chans1`) as a parameter of the class constructor. See page 218 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d04qgpf4d6s0"
      },
      "source": [
        "class NetWidth(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzE_vZCsTtiL"
      },
      "source": [
        "Train the previously defined model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqubKdgnd6s2",
        "outputId": "390062b1-65e1-4086-8821-7c7e786322cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model = NetWidth(n_chans1=32).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "\n",
        "all_acc_dict[\"width\"] = validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 18:03:09.547623 Epoch 1, Training loss 0.5444508557486686\n",
            "2020-10-03 18:03:13.137061 Epoch 10, Training loss 0.3170753327334762\n",
            "2020-10-03 18:03:17.169568 Epoch 20, Training loss 0.2745351647115817\n",
            "2020-10-03 18:03:21.119276 Epoch 30, Training loss 0.24255374937680116\n",
            "2020-10-03 18:03:25.178132 Epoch 40, Training loss 0.21334258348319182\n",
            "2020-10-03 18:03:29.318903 Epoch 50, Training loss 0.1869265928295008\n",
            "2020-10-03 18:03:33.381884 Epoch 60, Training loss 0.16310881932449947\n",
            "2020-10-03 18:03:37.339210 Epoch 70, Training loss 0.14082480271815495\n",
            "2020-10-03 18:03:41.311957 Epoch 80, Training loss 0.11995151366113098\n",
            "2020-10-03 18:03:45.340468 Epoch 90, Training loss 0.10072586221537393\n",
            "2020-10-03 18:03:49.395462 Epoch 100, Training loss 0.08321558117012309\n",
            "Accuracy train: 0.96\n",
            "Accuracy val: 0.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lrhLGeYT0RW"
      },
      "source": [
        "Check that the number of parameters of the wider model is higher than that of the previous model, due to the extra channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbgxYev6d6s4",
        "outputId": "2681e4b5-a43e-43c6-8016-4921017aabfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(p.numel() for p in model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Rv0aG6UF5Z"
      },
      "source": [
        "Redefine the training loop to include L2 regularization, also known as weight decay. See pages 219-220 of the book.\n",
        "\n",
        "Please note that the `l2_lambda` hyperparameter controls how strongly large weights are penalized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ULGKmrZd6s6"
      },
      "source": [
        "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn,\n",
        "                        train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            l2_lambda = 0.001\n",
        "            l2_norm = sum(p.pow(2.0).sum()\n",
        "                          for p in model.parameters())  # <1>\n",
        "            loss = loss + l2_lambda * l2_norm\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss_train += loss.item()\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGKtwQdXUyLl"
      },
      "source": [
        "Train the model with L2 regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWHgrlD5d6s8",
        "outputId": "ddf18184-b9f0-4fe2-d25c-6fe2eb0ef38c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model = Net().to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop_l2reg(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "all_acc_dict[\"l2 reg\"] = validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 18:03:50.235941 Epoch 1, Training loss 0.5842778145507642\n",
            "2020-10-03 18:03:55.028003 Epoch 10, Training loss 0.36634593224449524\n",
            "2020-10-03 18:04:00.554594 Epoch 20, Training loss 0.32257517868546165\n",
            "2020-10-03 18:04:05.918086 Epoch 30, Training loss 0.2961528061112021\n",
            "2020-10-03 18:04:11.349903 Epoch 40, Training loss 0.27755376971830986\n",
            "2020-10-03 18:04:16.746664 Epoch 50, Training loss 0.26365615019373073\n",
            "2020-10-03 18:04:22.136931 Epoch 60, Training loss 0.2515724055516492\n",
            "2020-10-03 18:04:27.569813 Epoch 70, Training loss 0.24009247911963494\n",
            "2020-10-03 18:04:33.089622 Epoch 80, Training loss 0.22937037563248044\n",
            "2020-10-03 18:04:38.525146 Epoch 90, Training loss 0.21903633013082918\n",
            "2020-10-03 18:04:43.934506 Epoch 100, Training loss 0.20924322819633848\n",
            "Accuracy train: 0.90\n",
            "Accuracy val: 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ7BwhdYU3n9"
      },
      "source": [
        "Define a subclass `NetDropout` of the `nn.Module` class that implements dropout to prevent overfitting. See pages 220-221 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5tjUIeud6s9"
      },
      "source": [
        "class NetDropout(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = self.conv1_dropout(out)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = self.conv2_dropout(out)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j267edOnWQeP"
      },
      "source": [
        "Train the model with dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKrSICbhd6s_",
        "outputId": "611b1be0-ad1a-4c25-88de-43c2110212c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model = NetDropout(n_chans1=32).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "all_acc_dict[\"dropout\"] = validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 18:04:44.642521 Epoch 1, Training loss 0.5800063126026445\n",
            "2020-10-03 18:04:48.546815 Epoch 10, Training loss 0.38075151071426977\n",
            "2020-10-03 18:04:52.921916 Epoch 20, Training loss 0.3490986672176677\n",
            "2020-10-03 18:04:57.251185 Epoch 30, Training loss 0.3297802624618931\n",
            "2020-10-03 18:05:01.573154 Epoch 40, Training loss 0.3125718879471919\n",
            "2020-10-03 18:05:05.912474 Epoch 50, Training loss 0.29208953223031037\n",
            "2020-10-03 18:05:10.175956 Epoch 60, Training loss 0.28206183538315405\n",
            "2020-10-03 18:05:14.415267 Epoch 70, Training loss 0.2723569439095297\n",
            "2020-10-03 18:05:18.647266 Epoch 80, Training loss 0.26272309443373587\n",
            "2020-10-03 18:05:22.986824 Epoch 90, Training loss 0.25365989014601253\n",
            "2020-10-03 18:05:27.312741 Epoch 100, Training loss 0.2399924808436898\n",
            "Accuracy train: 0.89\n",
            "Accuracy val: 0.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAhXeM5_WZit"
      },
      "source": [
        "Create a `NetBatchNorm` subclass of the `nn.Module` that implements batch normalization in order to speed up the learning and carry out regularization. See page 222 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjQwid4Ad6tA"
      },
      "source": [
        "class NetBatchNorm(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, \n",
        "                               padding=1)\n",
        "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.conv1_batchnorm(self.conv1(x))\n",
        "        out = F.max_pool2d(torch.tanh(out), 2)\n",
        "        out = self.conv2_batchnorm(self.conv2(out))\n",
        "        out = F.max_pool2d(torch.tanh(out), 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J0YBazGXKag"
      },
      "source": [
        "Train the model with batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFG0EHmcd6tC",
        "outputId": "e45e429b-9ba2-47f2-fadd-7f0ad3c2129d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model = NetBatchNorm(n_chans1=32).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "all_acc_dict[\"batch_norm\"] = validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 18:05:28.186618 Epoch 1, Training loss 0.47399871915009373\n",
            "2020-10-03 18:05:32.472403 Epoch 10, Training loss 0.25980775314531507\n",
            "2020-10-03 18:05:37.259258 Epoch 20, Training loss 0.19415953688940424\n",
            "2020-10-03 18:05:42.018627 Epoch 30, Training loss 0.14398394067101417\n",
            "2020-10-03 18:05:46.845721 Epoch 40, Training loss 0.10277671833184494\n",
            "2020-10-03 18:05:51.664310 Epoch 50, Training loss 0.0668683294681417\n",
            "2020-10-03 18:05:56.532233 Epoch 60, Training loss 0.04168906228343962\n",
            "2020-10-03 18:06:01.310366 Epoch 70, Training loss 0.028529456552640078\n",
            "2020-10-03 18:06:06.149025 Epoch 80, Training loss 0.016165737472000015\n",
            "2020-10-03 18:06:11.001029 Epoch 90, Training loss 0.08539414252925688\n",
            "2020-10-03 18:06:15.801016 Epoch 100, Training loss 0.008903632279349028\n",
            "Accuracy train: 1.00\n",
            "Accuracy val: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlRN4XciXV6X"
      },
      "source": [
        "Create a NetDepth subclass of the nn.Module class that implements a deeper neural architecture. See pages 223-224 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYaLIfa2d6tD"
      },
      "source": [
        "class NetDepth(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
        "                               kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
        "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYkPqL8qX5bQ"
      },
      "source": [
        "Train the deeper model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7u3-WEdd6tF",
        "outputId": "66d68616-dec0-476e-a25c-8e2fcd6f94bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model = NetDepth(n_chans1=32).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "all_acc_dict[\"depth\"] = validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 18:06:16.572636 Epoch 1, Training loss 0.6548030710524055\n",
            "2020-10-03 18:06:20.644653 Epoch 10, Training loss 0.33995750451543527\n",
            "2020-10-03 18:06:25.141102 Epoch 20, Training loss 0.3013665283181865\n",
            "2020-10-03 18:06:29.644013 Epoch 30, Training loss 0.27265951322142484\n",
            "2020-10-03 18:06:34.153608 Epoch 40, Training loss 0.24402576827319564\n",
            "2020-10-03 18:06:38.650839 Epoch 50, Training loss 0.21670965219189406\n",
            "2020-10-03 18:06:43.130695 Epoch 60, Training loss 0.19082109051145565\n",
            "2020-10-03 18:06:47.634764 Epoch 70, Training loss 0.1669179356544261\n",
            "2020-10-03 18:06:52.140406 Epoch 80, Training loss 0.14440111441027587\n",
            "2020-10-03 18:06:56.633855 Epoch 90, Training loss 0.12107962006880979\n",
            "2020-10-03 18:07:01.245959 Epoch 100, Training loss 0.09873796572351153\n",
            "Accuracy train: 0.95\n",
            "Accuracy val: 0.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e25O3spRYGCk"
      },
      "source": [
        "Create a `NetRes` subclass of the `nn.Module` class that defines a residual network. See pages 223-225 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgqOHcy5d6tJ"
      },
      "source": [
        "class NetRes(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
        "                               kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out1 = out\n",
        "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
        "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPrv3tpIYw6W"
      },
      "source": [
        "Train the residual network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rdsHi-Xd6tK",
        "outputId": "67eef435-bc3b-48cf-852e-e15fe5f21293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model = NetRes(n_chans1=32).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "all_acc_dict[\"res\"] = validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 18:07:02.018285 Epoch 1, Training loss 0.6650007108973849\n",
            "2020-10-03 18:07:06.218349 Epoch 10, Training loss 0.3292970836732038\n",
            "2020-10-03 18:07:10.882019 Epoch 20, Training loss 0.2861516498456335\n",
            "2020-10-03 18:07:15.432902 Epoch 30, Training loss 0.2552978458108416\n",
            "2020-10-03 18:07:20.007694 Epoch 40, Training loss 0.228219348296618\n",
            "2020-10-03 18:07:24.591479 Epoch 50, Training loss 0.20221760252099127\n",
            "2020-10-03 18:07:29.277774 Epoch 60, Training loss 0.17716037937600143\n",
            "2020-10-03 18:07:33.849279 Epoch 70, Training loss 0.15272267215001356\n",
            "2020-10-03 18:07:38.489067 Epoch 80, Training loss 0.12769096252170337\n",
            "2020-10-03 18:07:43.093121 Epoch 90, Training loss 0.10287515535523557\n",
            "2020-10-03 18:07:47.922339 Epoch 100, Training loss 0.0795267750598063\n",
            "Accuracy train: 0.96\n",
            "Accuracy val: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOFEUU4pZAj8"
      },
      "source": [
        "Create a `ResBlock` subclass of the `nn.Module` class that defines a block of convolution, activation and skip connection. See page 227 of the book. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR9-c23pd6tM"
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "                              padding=1, bias=False)  # <1>\n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
        "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
        "                                      nonlinearity='relu')  # <2>\n",
        "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch_norm(out)\n",
        "        out = torch.relu(out)\n",
        "        return out + x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uekDUXvwZZL0"
      },
      "source": [
        "Create a `NetResDeep` subclass of the `nn.Module` class that defines a very deep residual network composed of `ResBlock` blocks. The number of blocks is given by the `n_blocks` parameter to the class constructor. See page 227 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lhQ3tEWd6tP"
      },
      "source": [
        "class NetResDeep(nn.Module):\n",
        "    def __init__(self, n_chans1=32, n_blocks=10):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = self.resblocks(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAwYMCZ-Z43V"
      },
      "source": [
        "Train the very deep residual network composed of `ResBlock` blocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89pK-_39d6tQ",
        "outputId": "468790d8-bccf-4167-b1d9-dcb12b565f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model = NetResDeep(n_chans1=32, n_blocks=100).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "all_acc_dict[\"res deep\"] = validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 18:07:58.092228 Epoch 1, Training loss 2.273136031096149\n",
            "2020-10-03 18:09:26.758649 Epoch 10, Training loss 0.3788222589880038\n",
            "2020-10-03 18:11:05.044976 Epoch 20, Training loss 0.30534596247657847\n",
            "2020-10-03 18:12:43.850345 Epoch 30, Training loss 0.25487877960038036\n",
            "2020-10-03 18:14:22.806756 Epoch 40, Training loss 0.2085157937969372\n",
            "2020-10-03 18:16:01.583172 Epoch 50, Training loss 0.15721193136303288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSz-rqL_aNRd"
      },
      "source": [
        "Compare the performance of the previously trained models, in terms of training and validation accuracy. See pages 228-229 of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHkgE66xd6tT"
      },
      "source": [
        "trn_acc = [v['train'] for k, v in all_acc_dict.items()]\n",
        "val_acc = [v['val'] for k, v in all_acc_dict.items()]\n",
        "\n",
        "width =0.3\n",
        "plt.bar(np.arange(len(trn_acc)), trn_acc, width=width, label='train')\n",
        "plt.bar(np.arange(len(val_acc))+ width, val_acc, width=width, label='val')\n",
        "plt.xticks(np.arange(len(val_acc))+ width/2, list(all_acc_dict.keys()),\n",
        "           rotation=60)\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.savefig('accuracy_comparison.png', bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6LlYCBdd6tU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}